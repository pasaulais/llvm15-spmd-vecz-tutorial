* Introduction (2 min)
    Title

    What it is about?
        * Vectorizing
            -> Transform whole functions using LLVM
            -> "Horizontal" vectorization
        * SPMD programs
            -> Data-parallel execution model
            -> Used with compute frameworks like OpenCL and CUDA
        * for CPU-like processors, i.e. each core has
            -> A program counter
            -> Vector SIMD unit(s)

    Plan
    
Part 1 Background (10 min)
    SPMD Execution Model
        Data Parallel
            Work needs to be divided
        Single program
            Usually scalar
        Multiple instance running in parallel
            Each instance working on different data
            On GPU, implicit SIMD execution in lockstep
    
    SPMD Model: Division of Work
        Work-item:
            Unit of work
            One instance of a program
        Work-items executed in parallel by Execution Units
        Dimensions: 1D (array shape), 2D (grid shape), ...
        
        Simplistic Example:
            Massive Online Course
            Compute the overall grade of millions of students
            Overall grade is the weighted average of several grades
    
    SPMD Model: Single program
        kernel function
            entry point for computation
        executed once per work-item
            as if loop around it
            i = get_global_id(0)
        
        [code]
    
    Vertical Vectorization
        Within a single work-item
            e.g. loops within a kernel
            In our example, the weighted average computation
        Using the LLVM Loop Vectorizer
        However, not all kernels contain loops
        
        [graph of work-items with vertical loops]
    
    Horizontal Vectorization
        Many executions units each executing one instance of a single program 
            Fine on GPU (many EUs)
            Not so much on CPU (very few EUs)
            CPU has to execute many work-items sequentially
            
        Across work-items
            Compute multiple work-items at the same time
            Takes advantage of the execution model
        
        [graph of work-items with horizontal arrows]
    
    Glossary
        Work
            Work-item: unit of work to execute in parallel.
            Instance: State of one work-item.
            (SIMD) Lane: Execution of one instance, after vectorization.
        
        Data
            Packet: Contains several values/instructions, one per SIMD lane. Corresponds to one value/instruction in the original kernel.
            Uniform: Packet where values are identical for all lanes.
            Varying: Packet where values are not identical for all lanes.
        
        Control Flow        
            Uniform: Branch taken by all lanes.
            Divergent: Branch taken by some lanes. Requires special handling (No SIMD branching)
    
    How work-items map to hardware units
        * Not as clear as with GPUs, especially for VLIW processors
        
        * This is decided by the LLVM backend
        
        * Uniform instructions only executed once
    
    Comparison with other kinds of vectorizers
        * Loop Vectorizer
            * Can be used for both vertical and horizontal vectorization
            * Has to enforce dependencies between loop iterations
            * Execution order is not specified, this is not needed
            * Nested control-flow?
        
        * SLP Vectorizer
            * Finds groups of similar scalar instructions (same opcode)
            * Vertical vectorization
            * Not all kernels contain this kind of code
        
        * SPMD Vectorizer
            * Only supports horizontal vectorization
            * Nested control-flow
            * Not limited to a certain 'style' of code

Part 2 Implementing a basic vectorizer (25 min)
    What level? IR or MI
        Advantages and drawbacks of each approach
        * IR
        * MI -> mention Marcello's talk
        
    Structure
        * Pipeline design (stages)
            -> Each stage consists of one or more IR passes
            
        * Most stages require some analysis
            -> May be run mulitple times as stages invalidate it

    Stages
        * Preparation
        
        * Control flow conversion
        
        * Scalarization        
        
        * Packetization and instantiation
        
        * Optimizations and cleanup
    
    Implementation strategy
        * Create test kernels
            -> Start with very simple kernels (e.g. copy buffer, add two buffers)
            -> Gradually add more features (e.g. non-sequential memory accesses, vector instructions, etc)
        * Suggested implementation order
            -> Preparation and packetization first (required for simplest kernels)
            -> Then easier features: builtins, memory addressing, scalarization, instantiation
            -> More complex features last: control flow, optimizations
    
    
    
    Preparation
    
    Packetization
    
    Uniform value analysis
    
    Packetization: Phi nodes
    
    Memory addressing
        * Uniform address -> scalar loads and stores
        * Constant stride =1 -> vector laods and stores
        * Constant stride >1 -> interleaved loads and stores
        * Other -> gather loads, scatter stores
    
    Instantiation
    
    Scalarization
    
    Control flow conversion: if
    
    Masked memory operations
    
    Control flow conversion: loops
    
Part 3 Going further (10 min)
    SIMD width detection
    
    Handling builtin function calls
    
    Interleaved memory optimizations
    
    SoA to AoS conversion

* Conclusion (3 min)
